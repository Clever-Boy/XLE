// Copyright 2015 XLGAMES Inc.
//
// Distributed under the MIT License (See
// accompanying file "LICENSE" or the website
// http://www.opensource.org/licenses/mit-license.php)

#include "../illum.psh"

struct FragmentListNode
{
	uint	next;
	float	depth;
	uint	color;
};

uint FragmentListNode_PackColor(float4 color)
{
	color = saturate(color);
	return uint(color.a*255.f)<<24
		|  uint(color.r*255.f)<<16
		|  uint(color.g*255.f)<< 8
		|  uint(color.b*255.f)
		;
}

RWTexture2D<uint>						FragmentIds : register(u1);
RWStructuredBuffer<FragmentListNode>	NodesList	: register(u2);

Texture2D<float>						DuplicateOfDepthBuffer : register(t17);

void OutputFragmentNode(uint2 position, float4 color, float depth)
{
		//
		//	todo -- we could output a self balancing binary search tree...
		//			just might reduce the workload while resolving the sort
		//			order (particularly if we have a lot of elements, and need
		//			to do a partial sort)
		//				-- but it would require read/write access to NodesList,
		//					which might not be thread safe.
		//
	uint newNodeId = NodesList.IncrementCounter();
	uint oldNodeId;
	InterlockedExchange(FragmentIds[position], newNodeId, oldNodeId);

	FragmentListNode newNode;
	newNode.next = oldNodeId;
	newNode.depth = depth;
	newNode.color = FragmentListNode_PackColor(color);
	NodesList[newNodeId] = newNode;
}

//////////////////////////////////////////////////////////////////////////////////////////////////
		// Do the full lighting here --
		// 	actually, it might be better to do some of the lighting after resolve
		//	If we do a shadow lookup here (for example), it will mean doing a
		//	separate shadow lookup on each layer. But we might only really need
		//	that for the top-most few layers.
		//	One way to deal with this is to do an early depth pass that would set
		//	the depth buffer depth for fully opaque parts; or just after a fixed
		//	number of layers...?
float4 LightSample(GBufferValues sample, VSOutput geo, SystemInputs sys)
{
	float3 directionToEye = 0.0.xxx;
	#if (OUTPUT_WORLD_VIEW_VECTOR==1)
		directionToEye = normalize(geo.worldViewVector);
	#endif

	float4 result = float4(
		ResolveLitColor(
			sample, directionToEye, GetWorldPosition(geo),
			int2(geo.position.xy), GetSampleIndex(sys)), 1.f);

	#if OUTPUT_FOG_COLOR == 1
		result.rgb = lerp(geo.fogColor.rgb, result.rgb, geo.fogColor.a);
	#endif

	result.a = sample.blendingAlpha;
	return result;
}
//////////////////////////////////////////////////////////////////////////////////////////////////


//#if !((OUTPUT_TEXCOORD==1) && (MAT_ALPHA_TEST==1))
//	[earlydepthstencil]	// (this has a big effect, because otherwise UAV output wouldn't be occluded by depth buffer)
//#endif
float4 main_oi(VSOutput geo, SystemInputs sys) : SV_Target
{
		// Do depth rejection against the depth buffer duplicate early.
		// This prevents us having to do the lighting calculations (which might
		// be expensive) on hidden fragments.
		//
		// Note -- currently we're using a duplicate of the depth buffer here.
		//		but, maybe it would be better to unbind the depth buffer completely
		//		and just use the main depth buffer.
		//		Or, alternatively, keep the main depth buffer bound and disable
		//		writing, and use earlydepthstencil.
		//		But, if we do that we can't write depth information for opaque
		//		parts... that would only work well if we have a pre-depth
		//		pass for the fully opaque parts.

	float destinationDepth = DuplicateOfDepthBuffer[uint2(geo.position.xy)];
	float ndcComparison = geo.position.z; // / geo.position.w;
	if (ndcComparison > destinationDepth)
		discard;

	DoAlphaTest(geo);

	GBufferValues sample = IllumShader_PerPixel(geo);

		// note --  At alpha threshold, we just consider
		//			it opaque. It's a useful optimisation
		//			that goes hand in hand with the pre-depth pass.
	const float minAlpha =   1.f / 255.f;
	const float maxAlpha = AlphaThreshold; // 254.f / 255.f;
	if (sample.blendingAlpha < minAlpha) {
		discard;
	}

	float4 result = LightSample(sample, geo, sys);

		//
		//	Note -- we have to do a manual depth occlusion step here
		//			otherwise we might write out sampples to OutputFragmentNode
		//			that are actually depth-occluded
		//
		//			[earlydepthstencil] will also do depth occlusion
		//			before the shader... But it also writes to the
		//			depth buffer for all pixels (including "discard"ed)
		//			pixels... so we can't use that here.
		//

	if (result.a >= maxAlpha) {
		// uint oldValue;
		// InterlockedExchange(FragmentIds[uint2(geo.position.xy)], ~0, oldValue);
		return float4(LightingScale * result.rgb, 1.f); // result.a);
	} else {
			//	Multiply in alpha (if we're not using
			//	a premultiplied texture)
		#if !MAT_PREMULTIPLIED_ALPHA
			result.rgb *= result.a;
		#endif

		OutputFragmentNode(uint2(geo.position.xy), result, ndcComparison);
		discard;
		return 0.0.xxxx;
	}
}

///////////////////////////////////////////////////////////////////////////////////////////////////

Texture2DMS<float> StochasticOcclusionDepths : register(t9);

#define STOCHASTIC_SAMPLE_COUNT 8

[earlydepthstencil]
	float4 main_stochastic(VSOutput geo, SystemInputs sys) : SV_Target
{
	// This is the main resolve step when using stochastic blending
	// The brightness of the color we want to write should be modulated
	// by the alpha values of all of the layers on top of this one.
	//
	// But how to we know the alpha contribution of all of the layers
	// above this one?
	// Well, we can use the depth and alpha values written to the stochastic
	// buffers to create an estimate. It's not perfectly accurate, and it
	// is noisy, but it will give us a rough idea.

	float ndcComparison = geo.position.z; // / geo.position.w;

	float occlusion = 0.f;
	for (uint s=0; s<STOCHASTIC_SAMPLE_COUNT; ++s) {
		float sampleDepth = StochasticOcclusionDepths.Load(uint2(geo.position.xy), s);
		if (sampleDepth < ndcComparison) // (ndcComparison - 1e-4f))
			occlusion += 1.f;

		// if (ndcComparison < sampleDepth) discard;
	}
	occlusion /= float(STOCHASTIC_SAMPLE_COUNT);
	// occlusion = 0.f;

	GBufferValues sample = IllumShader_PerPixel(geo);
	// if (sample.blendingAlpha == 1.f) discard;
	float4 litValue = LightSample(sample, geo, sys);

	return float4((LightingScale * (1.f - occlusion) * litValue.a) * litValue.rgb, litValue.a);
}
