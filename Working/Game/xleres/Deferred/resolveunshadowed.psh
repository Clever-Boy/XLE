// Copyright 2015 XLGAMES Inc.
//
// Distributed under the MIT License (See
// accompanying file "LICENSE" or the website
// http://www.opensource.org/licenses/mit-license.php)

#if !defined(RESOLVE_UNSHADOWED_PSH)
#define RESOLVE_UNSHADOWED_PSH

#include "resolveutil.h"
#include "../Lighting/LightDesc.h"
#include "../Lighting/DirectionalResolve.h"
#include "../System/LoadGBuffer.h"
#include "../Colour.h" // for LightingScale

#if HAS_SCREENSPACE_AO==1
    Texture2D<float>			AmbientOcclusion		: register(t5);
#endif

cbuffer LightBuffer
{
	LightDesc Light;
}

float4 ResolveLightUnshadowed(	float4 position : SV_Position,
								float2 texCoord : TEXCOORD0,
								float3 viewFrustumVector : VIEWFRUSTUMVECTOR,
								SystemInputs sys) : SV_Target0
{
	int2 pixelCoords = position.xy;
	float3 worldPosition = CalculateWorldPosition(pixelCoords, GetSampleIndex(sys), viewFrustumVector);

	GBufferValues sample = LoadGBuffer(position, sys);

	float screenSpaceOcclusion = 1.f;
	#if HAS_SCREENSPACE_AO==1
        screenSpaceOcclusion = LoadFloat1(AmbientOcclusion, pixelCoords, GetSampleIndex(sys));
    #endif

	float3 directionToEye = normalize(-viewFrustumVector);
	float3 diffuse = LightResolve_Diffuse(sample, directionToEye, Light.NegativeDirection, Light);
	float3 specular = LightResolve_Specular(sample, directionToEye, Light.NegativeDirection, Light, screenSpaceOcclusion);

	const float lightScale = LightingScale;
	return float4(lightScale*(diffuse + specular), 1.f);
}

float ReciprocalMagnitude(float3 vec)
{
    // note -- is there a performance or accuracy advantage to doing it this way?
    return rsqrt(dot(vec, vec));
}

float3 RepresentativeVector_Sphere(float3 vectorToCenter, float lightRadius, float3 reflectionDir)
{
    // We want to find the "representative point" for a spherical light source
    // This is the point on the object that best represents the integral of all
    // incoming light. For a sphere, this is easy.. We just want to find the
    // point on the sphere closest to the reflection ray. This works so long as the
    // sphere is not (partially) below the equator. But we'll ignore the artefacts in
    // these cases.
    // See Brian Karis' 2013 Unreal course notes for more detail.
    // See also GPU Gems 5 for Drobot's research on this topic.
    // See also interesting shadertoy. "Distance Estimated Area Lights"
    //      https://www.shadertoy.com/view/4ss3Ws

    float3 L = vectorToCenter;
    float3 testPt = dot(reflectionDir, L) * reflectionDir;
    return lerp(L, testPt, saturate(lightRadius * ReciprocalMagnitude(testPt - L)));
}

float4 ResolveTubeLightUnshadowed(float4 position : SV_Position,
                                    float2 texCoord : TEXCOORD0,
                                    float3 viewFrustumVector : VIEWFRUSTUMVECTOR,
                                    SystemInputs sys) : SV_Target0;

float4 ResolveRectangleLightUnshadowed( float4 position : SV_Position,
                                        float2 texCoord : TEXCOORD0,
                                        float3 viewFrustumVector : VIEWFRUSTUMVECTOR,
                                        SystemInputs sys) : SV_Target0;

float4 ResolveSphereLightUnshadowed(float4 position : SV_Position,
									float2 texCoord : TEXCOORD0,
									float3 viewFrustumVector : VIEWFRUSTUMVECTOR,
									SystemInputs sys) : SV_Target0
{
    // return ResolveTubeLightUnshadowed(position, texCoord, viewFrustumVector, sys);
    return ResolveRectangleLightUnshadowed(position, texCoord, viewFrustumVector, sys);

    int2 pixelCoords = position.xy;
    float3 worldPosition = CalculateWorldPosition(pixelCoords, GetSampleIndex(sys), viewFrustumVector);
    GBufferValues sample = LoadGBuffer(position, sys);

    float screenSpaceOcclusion = 1.f;
    #if HAS_SCREENSPACE_AO==1
        screenSpaceOcclusion = LoadFloat1(AmbientOcclusion, pixelCoords, GetSampleIndex(sys));
    #endif

    float3 directionToEye = normalize(-viewFrustumVector);
    float3 reflectionDir = reflect(-directionToEye, sample.worldSpaceNormal);
    float3 lightNegDir = RepresentativeVector_Sphere(Light.NegativeDirection - worldPosition, Light.SourceRadius, reflectionDir);
    float distanceSq = dot(lightNegDir, lightNegDir);
    float rDistance = rsqrt(distanceSq);
    lightNegDir *= rDistance;

        // note --  Here we should really be doing some extra work to calculate the
        //          incoming light power. We need to define what the light power really
        //          means...? Is it irradiance? Or power per surface area? Or the power
        //          than an equivalent point light source would have?
        //      Right now we're going to ignore that, and just use trivial implementations.
        //      Also, if we were using a specular equation that is normalizes for energy
        //      conservation, we also need to make special changes here... Again, we'll ignore.

        // note -- on high roughness materials, the specular seems to have very little effect
        //      beyond short radius. We could probably find a cut-off point and disable specular
        //      based on distance, source radius & power, & material roughness

    float3 diffuse = LightResolve_Diffuse(sample, directionToEye, lightNegDir, Light);
    float3 specular = LightResolve_Specular(sample, directionToEye, lightNegDir, Light, screenSpaceOcclusion);

        // Specular attenuation is a little tricky here... We want the light
        // brightness to drop off relative to the solid angle of the light source.
        // Karis has a rough estimate to an sphere light version of GGX.
        // He suggests using the ratio of the normalization factors for this estimated
        // GGX with a direction light source GGX.
        // It feels like more work could be done here... It seems that the distant specular
        // highlights are still too bright. Probably it should be compared to a reference
        // ray tracer solution.
    float alpha = sample.material.roughness * sample.material.roughness;
    float alphaPrime = saturate(alpha + Light.SourceRadius * Light.SourceRadius * .5f * rDistance);
    float specAttenuation = (alpha * alpha) / (alphaPrime * alphaPrime);

    float distanceAttenuation = saturate(DistanceAttenuation(distanceSq, 1.f));
    float radiusDropOff = CalculateRadiusLimitAttenutation(distanceSq, Light.Radius);

    const float lightScale = LightingScale;
    return float4((lightScale*radiusDropOff*distanceAttenuation)*(diffuse + specAttenuation*specular), 1.f);
}

float TubeLightDiffuseIntegral(float3 L0, float3 L1, float3 N)
{
    // see the Unreal course notes and
    // http://www.cse.yorku.ca/~amana/research/linearLights.pdf

    float L0rmag = ReciprocalMagnitude(L0);
    float L1rmag = ReciprocalMagnitude(L1);
    float A = saturate(dot(N, L0) * .5f * L0rmag + dot(N, L1) * 0.5f * L1rmag);
    return 2.f * A / (1.f/(L0rmag*L1rmag) + dot(L0, L1) + 2.f);
}

float3 RepresentativeVector_Tube(float3 L0, float3 L1, float3 reflectionDir)
{
    float3 Ld = L1 - L0;
    float LdmagSq = dot(Ld, Ld);
    float RdotLd = dot(reflectionDir, Ld);
    float t = (dot(reflectionDir, L0) * RdotLd - dot(L0, Ld)) / (LdmagSq - RdotLd*RdotLd);
    return L0 + saturate(t) * Ld;
}

float4 ResolveTubeLightUnshadowed(
    float4 position : SV_Position,
    float2 texCoord : TEXCOORD0,
    float3 viewFrustumVector : VIEWFRUSTUMVECTOR,
    SystemInputs sys) : SV_Target0
{
    int2 pixelCoords = position.xy;
    float3 worldPosition = CalculateWorldPosition(pixelCoords, GetSampleIndex(sys), viewFrustumVector);
    GBufferValues sample = LoadGBuffer(position, sys);

    float screenSpaceOcclusion = 1.f;
    #if HAS_SCREENSPACE_AO==1
        screenSpaceOcclusion = LoadFloat1(AmbientOcclusion, pixelCoords, GetSampleIndex(sys));
    #endif

    float3 directionToEye = normalize(-viewFrustumVector);
    float3 reflectionDir = reflect(-directionToEye, sample.worldSpaceNormal);

        // As per Karis' 2013 Unreal course notes, we can calculate tube lights using
        // different methods for diffuse and specular.
        // For diffuse, we can directly calculate the integral of NdotL against a line
        // For specular, we use a representative point (similar to the sphere implementation)

    float3 L0 = Light.NegativeDirection;
    float lightLength = 5.f;
    float3 L1 = Light.NegativeDirection + float3(lightLength,0,0);

    float NdotL = TubeLightDiffuseIntegral(L0 - worldPosition, L1 - worldPosition, sample.worldSpaceNormal);

        // note --  After doing "RepresentativeVector_Tube" we could also use
        //          RepresentativeVector_Sphere to estimate a thick tube
    float3 tubePoint = RepresentativeVector_Tube(L0 - worldPosition, L1 - worldPosition, reflectionDir);
    float3 lightNegDir = RepresentativeVector_Sphere(tubePoint, Light.SourceRadius, reflectionDir);
    float distanceSq = dot(lightNegDir, lightNegDir);
    float rDistance = rsqrt(distanceSq);
    lightNegDir *= rDistance;

    float3 diffuse = LightResolve_Diffuse_NdotL(sample, directionToEye, lightNegDir, NdotL, Light);
    float3 specular = LightResolve_Specular(sample, directionToEye, lightNegDir, Light, screenSpaceOcclusion);

        // This specular attenutation method is based on Karis. Maybe it needs
        // a little more work...?
    float alpha = sample.material.roughness * sample.material.roughness;
    float alphaPrime0 = saturate(alpha + .25f * lightLength * lightLength * .5f * rDistance);
    float specAttenuation = alpha / alphaPrime0; // in principle the highlight is stretched in only one direction... so no square
    float alphaPrime1 = saturate(alpha + Light.SourceRadius * Light.SourceRadius * .5f * rDistance);
    specAttenuation *= (alpha * alpha) / (alphaPrime1 * alphaPrime1);

    float distanceAttenuation = saturate(DistanceAttenuation(distanceSq, 1.f));
    float radiusDropOff = CalculateRadiusLimitAttenutation(distanceSq, Light.Radius);

    const float lightScale = LightingScale;
    return float4((lightScale*radiusDropOff*distanceAttenuation)*(diffuse + specAttenuation*specular), 1.f);
}

float4 ResolveRectangleLightUnshadowed(
    float4 position : SV_Position,
    float2 texCoord : TEXCOORD0,
    float3 viewFrustumVector : VIEWFRUSTUMVECTOR,
    SystemInputs sys) : SV_Target0
{
    int2 pixelCoords = position.xy;
    float3 worldPosition = CalculateWorldPosition(pixelCoords, GetSampleIndex(sys), viewFrustumVector);
    GBufferValues sample = LoadGBuffer(position, sys);

    float screenSpaceOcclusion = 1.f;
    #if HAS_SCREENSPACE_AO==1
        screenSpaceOcclusion = LoadFloat1(AmbientOcclusion, pixelCoords, GetSampleIndex(sys));
    #endif

    float3 directionToEye = normalize(-viewFrustumVector);
    float3 reflectionDir = reflect(-directionToEye, sample.worldSpaceNormal);

        // This method based on Drobot's research in GPU Gems 5. It should be
        // fairly general, and it may be possible to adapt this method to
        // many different shapes.
        // For diffuse, we're going to use a kind of importance sampling
        // technique... Except that there will be only a single sample. We want
        // to find the single that sample that best represents the integral of
        // diffuse lighting over the whole shape.
        //
        // First, we need to find 2 points. The first point is the point on the
        // light plane that intersects the sample point normal. (p' or p0)
        // The second point is the projection of the sample point onto the light
        // plane along the plane normal (p'' or p1)
        //
        // We can define and light space where the light center is at the origin,
        // light is projected along -Z and +X and +Y lie on the light plane.
        // We can then choose to work either in world space or light space.
        // Let's use light space, because it might make doing boundary test
        // easier later.

    float3 planeNormal = float3(1,0,0);
    float3 planeTangent = float3(0,1,0);
    float3 planeBitangent = float3(0,0,1);
    float3 lightCenter = Light.NegativeDirection;
    float2 lightSize = float2(0.5f, 0.5f);

        // Here lightToWorld is an orthogonal rotation matrix (ie no scale)
        // so we can use simplified transformation operations.
    float3x3 lightToWorld = float3x3(planeTangent, planeBitangent, planeNormal);
    float3x3 worldToLight = transpose(lightToWorld);

    float3 samplePt = mul(worldToLight, worldPosition - lightCenter);
    float3 sampleNormal = mul(worldToLight, sample.worldSpaceNormal);
    float3 viewDirectionLight = mul(worldToLight, directionToEye);

        // Triple product type operation becomes simplier...
        // note -- obvious problems with sampleNormal.z is near 0
    float2 p0 = samplePt.xy + sampleNormal.xy * (-samplePt.z/sampleNormal.z);
    float2 p1 = samplePt.xy;    // note -- this has to be improved because the point can't fall under the sample horizon

        // In our coordinate system, pc and pt are easy to find
        // (though is can be more complex if one of the points falls under the sample horizon)
    float2 pc = float2(clamp(p0.x, -lightSize.x, lightSize.x), clamp(p0.y, -lightSize.y, lightSize.y));
    float2 pt = float2(clamp(p1.x, -lightSize.x, lightSize.x), clamp(p1.y, -lightSize.y, lightSize.y));

    float2 repPt = 0.5f * (pc+pt);
    float3 lightNegDir = float3(repPt - samplePt.xy, -samplePt.z);
    float distanceSq = dot(lightNegDir, lightNegDir);
    lightNegDir *= rsqrt(distanceSq);

        // We can just do the rest of the diffuse calculation in light space, also...
        // If it's just lambert, it's trivial.
    float NdotL = dot(sampleNormal, lightNegDir);
    float3 diffuse = LightResolve_Diffuse_NdotL(sample, viewDirectionLight, lightNegDir, NdotL, Light);

    float cosThetaLightPlane = sampleNormal.z;
    float area = lightSize.x * lightSize.y * 4.f;
    diffuse *= cosThetaLightPlane * area * saturate(DistanceAttenuation(distanceSq, 1.f));

    diffuse *= 100.f;

    float radiusDropOff = CalculateRadiusLimitAttenutation(distanceSq, Light.Radius);

    const float lightScale = LightingScale;
    return float4((lightScale*radiusDropOff)*(diffuse), 1.f);
}

#endif
