// Copyright 2015 XLGAMES Inc.
//
// Distributed under the MIT License (See
// accompanying file "LICENSE" or the website
// http://www.opensource.org/licenses/mit-license.php)

#if !defined(RESOLVE_UNSHADOWED_PSH)
#define RESOLVE_UNSHADOWED_PSH

#include "resolveutil.h"
#include "../Lighting/LightDesc.h"
#include "../Lighting/DirectionalResolve.h"
#include "../System/LoadGBuffer.h"
#include "../Colour.h" // for LightingScale

#if HAS_SCREENSPACE_AO==1
    Texture2D<float>			AmbientOcclusion		: register(t5);
#endif

cbuffer LightBuffer
{
	LightDesc Light;
}

float4 ResolveLightUnshadowed(	float4 position : SV_Position,
								float2 texCoord : TEXCOORD0,
								float3 viewFrustumVector : VIEWFRUSTUMVECTOR,
								SystemInputs sys) : SV_Target0
{
	int2 pixelCoords = position.xy;
	float3 worldPosition = CalculateWorldPosition(pixelCoords, GetSampleIndex(sys), viewFrustumVector);

	GBufferValues sample = LoadGBuffer(position, sys);

	float screenSpaceOcclusion = 1.f;
	#if HAS_SCREENSPACE_AO==1
        screenSpaceOcclusion = LoadFloat1(AmbientOcclusion, pixelCoords, GetSampleIndex(sys));
    #endif

	float3 directionToEye = normalize(-viewFrustumVector);
	float3 diffuse = LightResolve_Diffuse(sample, directionToEye, Light.NegativeDirection, Light);
	float3 specular = LightResolve_Specular(sample, directionToEye, Light.NegativeDirection, Light, screenSpaceOcclusion);

	const float lightScale = LightingScale;
	return float4(lightScale*(diffuse + specular), 1.f);
}

float ReciprocalMagnitude(float3 vec)
{
    // note -- is there a performance or accuracy advantage to doing it this way?
    return rsqrt(dot(vec, vec));
}

float MagnitudeSquared(float3 vec) { return dot(vec, vec); }

float3 RepresentativeVector_Sphere(float3 vectorToCenter, float lightRadius, float3 reflectionDir)
{
    // We want to find the "representative point" for a spherical light source
    // This is the point on the object that best represents the integral of all
    // incoming light. For a sphere, this is easy.. We just want to find the
    // point on the sphere closest to the reflection ray. This works so long as the
    // sphere is not (partially) below the equator. But we'll ignore the artefacts in
    // these cases.
    // See Brian Karis' 2013 Unreal course notes for more detail.
    // See also GPU Gems 5 for Drobot's research on this topic.
    // See also interesting shadertoy. "Distance Estimated Area Lights"
    //      https://www.shadertoy.com/view/4ss3Ws

    float3 L = vectorToCenter;
    float3 testPt = dot(reflectionDir, L) * reflectionDir;
    return lerp(L, testPt, saturate(lightRadius * ReciprocalMagnitude(testPt - L)));
}

float4 ResolveTubeLightUnshadowed(float4 position : SV_Position,
                                    float2 texCoord : TEXCOORD0,
                                    float3 viewFrustumVector : VIEWFRUSTUMVECTOR,
                                    SystemInputs sys) : SV_Target0;

float4 ResolveRectangleLightUnshadowed( float4 position : SV_Position,
                                        float2 texCoord : TEXCOORD0,
                                        float3 viewFrustumVector : VIEWFRUSTUMVECTOR,
                                        SystemInputs sys) : SV_Target0;

float4 ResolveSphereLightUnshadowed(float4 position : SV_Position,
									float2 texCoord : TEXCOORD0,
									float3 viewFrustumVector : VIEWFRUSTUMVECTOR,
									SystemInputs sys) : SV_Target0
{
    // return ResolveTubeLightUnshadowed(position, texCoord, viewFrustumVector, sys);
    return ResolveRectangleLightUnshadowed(position, texCoord, viewFrustumVector, sys);

    int2 pixelCoords = position.xy;
    float3 worldPosition = CalculateWorldPosition(pixelCoords, GetSampleIndex(sys), viewFrustumVector);
    GBufferValues sample = LoadGBuffer(position, sys);

    float screenSpaceOcclusion = 1.f;
    #if HAS_SCREENSPACE_AO==1
        screenSpaceOcclusion = LoadFloat1(AmbientOcclusion, pixelCoords, GetSampleIndex(sys));
    #endif

    float3 directionToEye = normalize(-viewFrustumVector);
    float3 reflectionDir = reflect(-directionToEye, sample.worldSpaceNormal);
    float3 lightNegDir = RepresentativeVector_Sphere(Light.NegativeDirection - worldPosition, Light.SourceRadius, reflectionDir);
    float distanceSq = dot(lightNegDir, lightNegDir);
    float rDistance = rsqrt(distanceSq);
    lightNegDir *= rDistance;

        // note --  Here we should really be doing some extra work to calculate the
        //          incoming light power. We need to define what the light power really
        //          means...? Is it irradiance? Or power per surface area? Or the power
        //          than an equivalent point light source would have?
        //      Right now we're going to ignore that, and just use trivial implementations.
        //      Also, if we were using a specular equation that is normalizes for energy
        //      conservation, we also need to make special changes here... Again, we'll ignore.

        // note -- on high roughness materials, the specular seems to have very little effect
        //      beyond short radius. We could probably find a cut-off point and disable specular
        //      based on distance, source radius & power, & material roughness

    float3 diffuse = LightResolve_Diffuse(sample, directionToEye, lightNegDir, Light);
    float3 specular = LightResolve_Specular(sample, directionToEye, lightNegDir, Light, screenSpaceOcclusion);

        // Specular attenuation is a little tricky here... We want the light
        // brightness to drop off relative to the solid angle of the light source.
        // Karis has a rough estimate to an sphere light version of GGX.
        // He suggests using the ratio of the normalization factors for this estimated
        // GGX with a direction light source GGX.
        // It feels like more work could be done here... It seems that the distant specular
        // highlights are still too bright. Probably it should be compared to a reference
        // ray tracer solution.
    float alpha = sample.material.roughness * sample.material.roughness;
    float alphaPrime = saturate(alpha + Light.SourceRadius * Light.SourceRadius * .5f * rDistance);
    float specAttenuation = (alpha * alpha) / (alphaPrime * alphaPrime);

    float distanceAttenuation = saturate(DistanceAttenuation(distanceSq, 1.f));
    float radiusDropOff = CalculateRadiusLimitAttenutation(distanceSq, Light.Radius);

    const float lightScale = LightingScale;
    return float4((lightScale*radiusDropOff*distanceAttenuation)*(diffuse + specAttenuation*specular), 1.f);
}

float TubeLightDiffuseIntegral(float3 L0, float3 L1, float3 N)
{
    // see the Unreal course notes and
    // http://www.cse.yorku.ca/~amana/research/linearLights.pdf

    float L0rmag = ReciprocalMagnitude(L0);
    float L1rmag = ReciprocalMagnitude(L1);
    float A = saturate(dot(N, L0) * .5f * L0rmag + dot(N, L1) * 0.5f * L1rmag);
    return 2.f * A / (1.f/(L0rmag*L1rmag) + dot(L0, L1) + 2.f);
}

float3 RepresentativeVector_Tube(float3 L0, float3 L1, float3 reflectionDir)
{
    float3 Ld = L1 - L0;
    float LdmagSq = dot(Ld, Ld);
    float RdotLd = dot(reflectionDir, Ld);
    float t = (dot(reflectionDir, L0) * RdotLd - dot(L0, Ld)) / (LdmagSq - RdotLd*RdotLd);
    return L0 + saturate(t) * Ld;
}

float4 ResolveTubeLightUnshadowed(
    float4 position : SV_Position,
    float2 texCoord : TEXCOORD0,
    float3 viewFrustumVector : VIEWFRUSTUMVECTOR,
    SystemInputs sys) : SV_Target0
{
    int2 pixelCoords = position.xy;
    float3 worldPosition = CalculateWorldPosition(pixelCoords, GetSampleIndex(sys), viewFrustumVector);
    GBufferValues sample = LoadGBuffer(position, sys);

    float screenSpaceOcclusion = 1.f;
    #if HAS_SCREENSPACE_AO==1
        screenSpaceOcclusion = LoadFloat1(AmbientOcclusion, pixelCoords, GetSampleIndex(sys));
    #endif

    float3 directionToEye = normalize(-viewFrustumVector);
    float3 reflectionDir = reflect(-directionToEye, sample.worldSpaceNormal);

        // As per Karis' 2013 Unreal course notes, we can calculate tube lights using
        // different methods for diffuse and specular.
        // For diffuse, we can directly calculate the integral of NdotL against a line
        // For specular, we use a representative point (similar to the sphere implementation)

    float3 L0 = Light.NegativeDirection;
    float lightLength = 5.f;
    float3 L1 = Light.NegativeDirection + float3(lightLength,0,0);

    float NdotL = TubeLightDiffuseIntegral(L0 - worldPosition, L1 - worldPosition, sample.worldSpaceNormal);

        // note --  After doing "RepresentativeVector_Tube" we could also use
        //          RepresentativeVector_Sphere to estimate a thick tube
    float3 tubePoint = RepresentativeVector_Tube(L0 - worldPosition, L1 - worldPosition, reflectionDir);
    float3 lightNegDir = RepresentativeVector_Sphere(tubePoint, Light.SourceRadius, reflectionDir);
    float distanceSq = dot(lightNegDir, lightNegDir);
    float rDistance = rsqrt(distanceSq);
    lightNegDir *= rDistance;

    float3 diffuse = LightResolve_Diffuse_NdotL(sample, directionToEye, lightNegDir, NdotL, Light);
    float3 specular = LightResolve_Specular(sample, directionToEye, lightNegDir, Light, screenSpaceOcclusion);

        // This specular attenutation method is based on Karis. Maybe it needs
        // a little more work...?
    float alpha = sample.material.roughness * sample.material.roughness;
    float alphaPrime0 = saturate(alpha + .25f * lightLength * lightLength * .5f * rDistance);
    float specAttenuation = alpha / alphaPrime0; // in principle the highlight is stretched in only one direction... so no square
    float alphaPrime1 = saturate(alpha + Light.SourceRadius * Light.SourceRadius * .5f * rDistance);
    specAttenuation *= (alpha * alpha) / (alphaPrime1 * alphaPrime1);

    float distanceAttenuation = saturate(DistanceAttenuation(distanceSq, 1.f));
    float radiusDropOff = CalculateRadiusLimitAttenutation(distanceSq, Light.Radius);

    const float lightScale = LightingScale;
    return float4((lightScale*radiusDropOff*distanceAttenuation)*(diffuse + specAttenuation*specular), 1.f);
}

float RectRectIntersectionArea(
    out float2 representativePoint,
    float2 R0min, float2 R0max, float2 R1min, float2 R1max)
{
    float2 intersectionMin = max(R0min, R1min);
    float2 intersectionMax = min(R0max, R1max);
    float2 A = intersectionMax - intersectionMin;
    representativePoint = .5f * (intersectionMin + intersectionMax);
    return max(0, A.x) * max(0, A.y);
}

float TrowReitzDInverse(float D, float alpha)
{
    // This is the inverse of the GGX "D" normal distribution
    // function. We only care about the [0,1] part -- so we can
    // ignore some secondary solutions.
    //
    // float alphaSq = alpha * alpha;
    // float denom = 1.f + (alphaSq - 1.f) * NdotH * NdotH;
    // return alphaSq / (pi * denom * denom);
    //
    // For 0 <= alpha < 1, there is always a solution for D above around 0.3182
    // For smaller D values, there sometimes is not a solution.

    float alphaSq = alpha * alpha;
    float A = sqrt(alphaSq / (pi*D)) - 1.f;
    float B = A / (alphaSq - 1.f);
    if (B < 0.f) return 0.f;    // these cases have no solution
    return saturate(sqrt(B));
}

float TrowReitzDInverseApprox(float alpha)
{
    // This is an approximation of TrowReitzDInverseApprox(0.32f, alpha);
    // It's based on a Taylor series.
    // It's fairly accurate for alpha < 0.5... Above that it tends to fall
    // off. The third order approximation is better above alpha .5. But really
    // small alpha values are more important, so probably it's fine.
    // third order: y=.913173-0.378603(a-.2)+0.239374(a-0.2)^2-0.162692(a-.2)^3
    // For different "cut-off" values of D, we need to recalculate the Taylor series.

    float b = alpha - .2f;
    return .913173f - 0.378603f * b + .239374f * b * b;
}

float4 ResolveRectangleLightUnshadowed(
    float4 position : SV_Position,
    float2 texCoord : TEXCOORD0,
    float3 viewFrustumVector : VIEWFRUSTUMVECTOR,
    SystemInputs sys) : SV_Target0
{
    int2 pixelCoords = position.xy;
    float3 worldPosition = CalculateWorldPosition(pixelCoords, GetSampleIndex(sys), viewFrustumVector);
    GBufferValues sample = LoadGBuffer(position, sys);

    float screenSpaceOcclusion = 1.f;
    #if HAS_SCREENSPACE_AO==1
        screenSpaceOcclusion = LoadFloat1(AmbientOcclusion, pixelCoords, GetSampleIndex(sys));
    #endif

    float3 directionToEye = normalize(-viewFrustumVector);

        // This method based on Drobot's research in GPU Gems 5. It should be
        // fairly general, and it may be possible to adapt this method to
        // many different shapes.
        // For diffuse, we're going to use a kind of importance sampling
        // technique... Except that there will be only a single sample. We want
        // to find the single that sample that best represents the integral of
        // diffuse lighting over the whole shape.
        //
        // First, we need to find 2 points. The first point is the point on the
        // light plane that intersects the sample point normal. (p' or p0)
        // The second point is the projection of the sample point onto the light
        // plane along the plane normal (p'' or p1)
        //
        // We can define and light space where the light center is at the origin,
        // light is projected along +Z and +X and +Y lie on the light plane.
        // We can then choose to work either in world space or light space.
        // Let's use light space, because it might make doing boundary test
        // easier later.
        // It might be that working in world space could end up being fewer
        // calculations, but we've have to try it to find out.

    float3 planeNormal = float3(1,0,0);
    float3 planeTangent = float3(0,1,0);
    float3 planeBitangent = float3(0,0,1);
    float3 lightCenter = Light.NegativeDirection;
    float2 lightSize = float2(Light.SourceRadius, Light.SourceRadius);

        // Here lightToWorld is an orthogonal rotation matrix (ie no scale)
        // so we can use simplified transformation operations.
    float3x3 worldToLight = float3x3(planeTangent, planeBitangent, planeNormal);

    float3 samplePt = mul(worldToLight, worldPosition - lightCenter);
    float3 sampleNormal = mul(worldToLight, sample.worldSpaceNormal);
    float3 viewDirectionLight = mul(worldToLight, directionToEye);

    if (samplePt.z < 0.f) return float4(0.0.xxx, 1.f);

    // if (abs(sampleNormal.z) < 1e-3f) sampleNormal += float3(0.03f, 0.03f, 0.03f);

        // We need to skew in these cases to find a collision point.
    bool isFacingAway = sampleNormal.z >= 0.f;
    float3 skewedNormal = sampleNormal;
    if (isFacingAway) skewedNormal = normalize(sampleNormal-float3(0,0,.5f));

        // Triple product type operation becomes simplier...
        // note -- obvious problems with sampleNormal.z is near 0
    float2 p0 = samplePt.xy + skewedNormal.xy * (-samplePt.z/skewedNormal.z);
    float2 p1 = samplePt.xy;

        // We need to prevent p1 from falling beneath the horizon...
    // float2 projHorizNormal = normalize(sampleNormal.xy);
    // p1 -= projHorizNormal * min(0, dot(p1 - p0, projHorizNormal));
    if (isFacingAway) {
            // Let's find the direction along the horizon plane to the light
            // We can do this by removing the part of the direction that is
            // perpendicular to the normal (thereby creating a vector that is
            // tangent to the horizon plane)
        float3 directionAlongHorizon = -samplePt;
        directionAlongHorizon -= dot(directionAlongHorizon, sampleNormal) * directionAlongHorizon;
        p1 = samplePt.xy - directionAlongHorizon.xy * (samplePt.z / directionAlongHorizon.z);
    }

        // In our coordinate system, pc and pt are easy to find
        // (though is can be more complex if one of the points falls under the sample horizon)
        // Drobot didn't actually calculate pc and pt -- he just used a half way point
        // between p0 and p1. Actually, the difference does seem to be quite minor.
        // But in light space, it's easy to clamp pc and pt.
    float2 pc = float2(clamp(p0.x, -lightSize.x, lightSize.x), clamp(p0.y, -lightSize.y, lightSize.y));
    float2 pt = float2(clamp(p1.x, -lightSize.x, lightSize.x), clamp(p1.y, -lightSize.y, lightSize.y));

    float2 repPt = 0.5f * (pc+pt);
    float3 lightNegDir = float3(repPt - samplePt.xy, -samplePt.z);
    float distanceSq = dot(lightNegDir, lightNegDir);
    lightNegDir *= rsqrt(distanceSq);

        // We can just do the rest of the diffuse calculation in light space, also...
        // If it's just lambert, it's trivial.
    float NdotL = saturate(dot(sampleNormal, lightNegDir));
    float3 diffuse = LightResolve_Diffuse_NdotL(sample, viewDirectionLight, lightNegDir, NdotL, Light);

        // note --  There's some confusinn about this cosThetaLightPlane equation.
        //          here we're calculating the area of the that that is visible from
        //          the persepective of the sample point. It seems best to use the
        //          dot product of the light plane with the light direction
    float cosThetaLightPlane = saturate(-lightNegDir.z);
    float area = lightSize.x * lightSize.y * 4.f;
    float diffuseAttenuation = area * cosThetaLightPlane * saturate(DistanceAttenuation(distanceSq, 1.f));

        // To calculate specular, we need a different equation. We're going to
        // create a cone centered around the reflection angle. The angle of the cone
        // should be based on the specular equation -- in particular, the normal
        // distribution term of the micro-facet equation.
        // We will project the cone onto the light plane, and we want to find the area
        // of the intersection of the cone and the light.
        // We're going to use the ratio of the intersection area with the full light area
        // to modulate the specular equation. This is an approximation of the integral
        // incoming light weighted by the normal distribution function.
        //
        // A projected cone is a complex shape. So we're not going to use it directly.
        // Instead, we approximate the projected cone as just a square on the light
        // plane. First we find a disk approximating the projected cone. Then we find
        // a square that is adjusted to have the same area.
        //
        // Let's try doing this in light space, as well.

    float3 reflectedDirLight = reflect(-viewDirectionLight, sampleNormal);

        // We can calculate an estimate for the cone angle by using the inverse of the
        // normal distribution function. The NDF gives us an intensity value for an input
        // cosTheta (where theta is the angle between N and H). We can go backwards by
        // finding the cosTheta that gives us a certain intensity value. The inverse can
        // give us a cone on which the D value is a given intensity. So let's pick some
        // cut-off value, and use that. 0.312 is convenient because of the definition of
        // our NDF.
        // The full inverse for GGX Trowbridge Reitz is a little too expensive. And the
        // end result is fairly subtle... So we get by with a rough estimate.
        //
        // The clearest artefact we get is problems on grazing angles when the light
        // source is near a surface (ie, a wall length light source gets distorted
        // in the floor). The effect is increased with smaller cutoff values here...
        // Very small cutoff angles almost seem to give the best result.
    // float cosConeAngle = TrowReitzDInverse(0.32f, RoughnessToDAlpha(sample.material.roughness));
    // float cosConeAngle = TrowReitzDInverse(0.97f, RoughnessToDAlpha(sample.material.roughness));
    float cosConeAngle = TrowReitzDInverseApprox(RoughnessToDAlpha(sample.material.roughness));

        // note --  we could incorporate this tanConeAngle calculation into the
        //          TrowReitzDInverseApprox function...?
    float sinConeAngle = sqrt(1.f - cosConeAngle*cosConeAngle);
    float tanConeAngle = sinConeAngle/cosConeAngle;

        // The projected circle radius value here is only accurate when the direction
        // to the light is along the reflection dir (but that's also when the highlight is
        // brightest)
    float distToProjectedConeCenter = (-samplePt.z/reflectedDirLight.z);
    float2 projectedCircleCenter = samplePt.xy + reflectedDirLight.xy * distToProjectedConeCenter;
    float projectedCircleRadius = max(0, distToProjectedConeCenter * tanConeAngle);
    // return float4(projectedCircleRadius.xxx, 1.f);

        // This is squaring the circle...?!
        // float circleArea = pi * projectedCircleRadius * projectedCircleRadius;
        // float squareSide = sqrt(circleArea);
    float squareRadius = halfSqrtPi * projectedCircleRadius;

    float2 representativePt;
    float intersectionArea = RectRectIntersectionArea(
        representativePt,
        -lightSize, lightSize,
        projectedCircleCenter - float2(squareRadius, squareRadius),
        projectedCircleCenter + float2(squareRadius, squareRadius));

    // representativePt = projectedCircleCenter;

    float integralApprox = intersectionArea / (area + 1e-3f);
    // return float4(integralApprox.xxx, 1.f);

    float3 specLightNegDir = float3(representativePt - samplePt.xy, -samplePt.z);
    float specDistanceSq = MagnitudeSquared(specLightNegDir);
    specLightNegDir *= rsqrt(specDistanceSq);
    sample.worldSpaceNormal = sampleNormal;

        // note --  We can get some interesting results if we use "lightNegDir" here instead of
        //          specLightNegDir -- it's a good way to visualise the representative poitn we're using
        //          for the diffuse calculation.
    float3 specular = LightResolve_Specular(sample, viewDirectionLight, specLightNegDir, Light, screenSpaceOcclusion);
    float specAttenuation = area * integralApprox * saturate(DistanceAttenuation(specDistanceSq, 1.f));

    float radiusDropOff = CalculateRadiusLimitAttenutation(distanceSq, Light.Radius);

    const float lightScale = LightingScale;
    return float4((lightScale*radiusDropOff)*(diffuseAttenuation * diffuse + specAttenuation * specular), 1.f);
}

#endif
